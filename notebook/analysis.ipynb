{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 500 Backtesting - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis on the S&P 500 stock price data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "from memory_reducer import memory_reducer\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Memory Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data with memory optimization\n",
    "prices = memory_reducer('../data/prices.csv')\n",
    "sp500 = memory_reducer('../data/sp500.csv')\n",
    "\n",
    "print(\"Prices data shape:\", prices.shape)\n",
    "print(\"S&P 500 data shape:\", sp500.shape)\n",
    "print(\"\\nPrices columns:\", prices.columns.tolist())\n",
    "print(\"S&P 500 columns:\", sp500.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values in prices data\n",
    "print(\"Missing values in prices data:\")\n",
    "print(prices.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {prices.isnull().sum().sum()}\")\n",
    "print(f\"Percentage of missing values: {(prices.isnull().sum().sum() / prices.size) * 100:.2f}%\")\n",
    "\n",
    "# Missing values in S&P 500 data\n",
    "print(\"\\nMissing values in S&P 500 data:\")\n",
    "print(sp500.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values pattern\n",
    "plt.figure(figsize=(12, 6))\n",
    "prices_sample = prices.sample(n=min(10000, len(prices)))  # Sample for visualization\n",
    "sns.heatmap(prices_sample.isnull(), cbar=True, yticklabels=False)\n",
    "plt.title('Missing Values Pattern in Stock Prices Data (Sample)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/missing_values_heatmap.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Outliers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price distribution analysis\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(prices['price'].dropna(), bins=100, alpha=0.7)\n",
    "plt.title('Price Distribution')\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(np.log(prices['price'].dropna() + 1), bins=100, alpha=0.7)\n",
    "plt.title('Log Price Distribution')\n",
    "plt.xlabel('Log(Price + 1)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.boxplot(prices['price'].dropna())\n",
    "plt.title('Price Box Plot')\n",
    "plt.ylabel('Price ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/price_distribution_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Price statistics:\")\n",
    "print(prices['price'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify extreme outliers\n",
    "price_q99 = prices['price'].quantile(0.99)\n",
    "price_q01 = prices['price'].quantile(0.01)\n",
    "\n",
    "extreme_high = prices[prices['price'] > price_q99]\n",
    "extreme_low = prices[prices['price'] < price_q01]\n",
    "\n",
    "print(f\"Extreme high prices (>99th percentile, ${price_q99:.2f}):\")\n",
    "print(extreme_high.nlargest(10, 'price')[['ticker', 'date', 'price']])\n",
    "\n",
    "print(f\"\\nExtreme low prices (<1st percentile, ${price_q01:.2f}):\")\n",
    "print(extreme_low.nsmallest(10, 'price')[['ticker', 'date', 'price']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Price Consistency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime for analysis\n",
    "prices['date'] = pd.to_datetime(prices['date'])\n",
    "\n",
    "# Average price over time\n",
    "avg_price_over_time = prices.groupby('date')['price'].mean()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(avg_price_over_time.index, avg_price_over_time.values)\n",
    "plt.title('Average Stock Price Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Average Price ($)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/average_price_over_time.png')\n",
    "plt.show()\n",
    "\n",
    "# Average price by company\n",
    "company_avg_prices = prices.groupby('ticker')['price'].mean().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.bar(range(len(company_avg_prices)), company_avg_prices.values)\n",
    "plt.title('Average Price for Each Company in Dataset')\n",
    "plt.xlabel('Company (Ticker)')\n",
    "plt.ylabel('Average Price ($)')\n",
    "plt.xticks(range(0, len(company_avg_prices), max(1, len(company_avg_prices)//10)), \n",
    "           company_avg_prices.index[::max(1, len(company_avg_prices)//10)], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/average_price_by_company.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price consistency across companies\n",
    "company_stats = prices.groupby('ticker')['price'].agg(['mean', 'std', 'count']).reset_index()\n",
    "company_stats['cv'] = company_stats['std'] / company_stats['mean']  # Coefficient of variation\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(company_stats['mean'], bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Average Prices by Company')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.ylabel('Number of Companies')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(company_stats['cv'], bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Price Volatility (CV) by Company')\n",
    "plt.xlabel('Coefficient of Variation')\n",
    "plt.ylabel('Number of Companies')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.scatter(company_stats['mean'], company_stats['std'], alpha=0.6)\n",
    "plt.title('Price Mean vs Standard Deviation')\n",
    "plt.xlabel('Average Price ($)')\n",
    "plt.ylabel('Price Standard Deviation')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.hist(company_stats['count'], bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Data Points per Company')\n",
    "plt.xlabel('Number of Data Points')\n",
    "plt.ylabel('Number of Companies')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/plots/price_consistency_analysis.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most volatile companies (by CV):\")\n",
    "print(company_stats.nlargest(10, 'cv')[['ticker', 'mean', 'std', 'cv']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Outlier Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and document specific outliers\n",
    "outliers_list = []\n",
    "\n",
    "# Method 1: Statistical outliers using IQR\n",
    "for ticker in prices['ticker'].unique()[:50]:  # Sample first 50 tickers\n",
    "    ticker_data = prices[prices['ticker'] == ticker]\n",
    "    if len(ticker_data) > 10:  # Only analyze tickers with sufficient data\n",
    "        Q1 = ticker_data['price'].quantile(0.25)\n",
    "        Q3 = ticker_data['price'].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = ticker_data[(ticker_data['price'] < lower_bound) | \n",
    "                              (ticker_data['price'] > upper_bound)]\n",
    "        \n",
    "        for _, row in outliers.head(2).iterrows():  # Take top 2 outliers per ticker\n",
    "            outliers_list.append({\n",
    "                'ticker': row['ticker'],\n",
    "                'date': row['date'].strftime('%Y-%m-%d'),\n",
    "                'price': row['price']\n",
    "            })\n",
    "\n",
    "# Display first 5 outliers\n",
    "print(\"Top 5 identified outliers:\")\n",
    "for i, outlier in enumerate(outliers_list[:5]):\n",
    "    print(f\"{i+1}. Ticker: {outlier['ticker']}, Date: {outlier['date']}, Price: ${outlier['price']:.4f}\")\n",
    "\n",
    "# Save to file\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "with open('../results/outliers.txt', 'w') as f:\n",
    "    f.write(\"ticker,date,price\\n\")\n",
    "    for outlier in outliers_list[:5]:\n",
    "        f.write(f\"{outlier['ticker']},{outlier['date']},{outlier['price']:.4f}\\n\")\n",
    "\n",
    "print(\"\\nOutliers saved to ../results/outliers.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"====================\")\n",
    "print(f\"Total records: {len(prices):,}\")\n",
    "print(f\"Unique tickers: {prices['ticker'].nunique()}\")\n",
    "print(f\"Date range: {prices['date'].min()} to {prices['date'].max()}\")\n",
    "print(f\"Missing values: {prices.isnull().sum().sum():,} ({(prices.isnull().sum().sum() / prices.size) * 100:.2f}%)\")\n",
    "print(f\"Price range: ${prices['price'].min():.4f} to ${prices['price'].max():.2f}\")\n",
    "print(f\"Median price: ${prices['price'].median():.2f}\")\n",
    "print(f\"Potential outliers identified: {len(outliers_list)}\")\n",
    "\n",
    "print(\"\\nKey data quality issues identified:\")\n",
    "print(\"- Significant missing values requiring forward-fill strategy\")\n",
    "print(\"- Extreme price outliers requiring filtering\")\n",
    "print(\"- Price spikes that may indicate stock splits or data errors\")\n",
    "print(\"- Varying data availability across different tickers\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}